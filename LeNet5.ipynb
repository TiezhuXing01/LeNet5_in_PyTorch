{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选择GPU还是CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建 LeNet5 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义名为 LeNet5 的类，该类继承自 nn.Module\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # 卷积层 1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\t# 卷积\n",
    "            nn.BatchNorm2d(6),\t\t# 批归一化\n",
    "            nn.ReLU(),)\n",
    "        # 下采样\n",
    "        self.subsampel1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\t\t# 最大池化\n",
    "        # 卷积层 2\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),)\n",
    "        # 下采样\n",
    "        self.subsampel2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        # 全连接\n",
    "        self.L1 = nn.Linear(400, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.L2 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.L3 = nn.Linear(84, num_classes)\n",
    "    # 前向传播\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.subsampel1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.subsampel2(out)\n",
    "        # 将上一步输出的16个5×5特征图中的400个像素展平成一维向量，以便下一步全连接\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        # 全连接\n",
    "        out = self.L1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.L2(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.L3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据集\n",
    "本例中，我们使用torchvision中的MNIST数据集，该数据集包含了60000张手写数字的图片，每张图片都是28*28的灰度图，其分为训练集和测试集，其中训练集有50000张，测试集有10000张。我们将使用torchvision中的transforms模块来对数据进行预处理，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练集\n",
    "train_dataset = torchvision.datasets.MNIST(root = './data',\t# 数据集保存路径\n",
    "                                           train = True,\t# 是否为训练集\n",
    "                                           # 数据预处理\n",
    "                                           transform = transforms.Compose([\n",
    "                                                  transforms.Resize((32,32)),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean = (0.1307,), \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t                     std = (0.3081,))]),\n",
    "                                           download = True)\t#是否下载\n",
    " \n",
    "# 加载测试集\n",
    "test_dataset = torchvision.datasets.MNIST(root = './data',\n",
    "                                          train = False,\n",
    "                                          transform = transforms.Compose([\n",
    "                                                  transforms.Resize((32,32)),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean = (0.1325,), \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t                     std = (0.3105,))]),\n",
    "                                          download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据\n",
    "用DataLoader加载MNIST数据集，DataLoader是一个数据加载器，可以加载并处理数据集中的数据，然后通过它返回一个batch的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一次抓64张牌\n",
    "batch_size = 64\n",
    "# 加载训练数据\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\t# 是否打乱\n",
    "# 加载测试数据\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = False)\t# 是否打乱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "model = LeNet5(num_classes).to(device)\n",
    "\n",
    "cost = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练 LeNet5 网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置一共训练几轮（epoch）\n",
    "num_epochs = 10\n",
    "# 外部循环用于遍历轮次\n",
    "for epoch in range(num_epochs):\n",
    "    # 内部循环用于遍历每轮中的所有批次\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    " \n",
    "        # 前向传播\n",
    "        outputs = model(images)   # 通过模型进行前向传播，得到模型的预测结果 outputs\n",
    "        loss = cost(outputs, labels)\t# 计算模型预测与真实标签之间的损失\n",
    " \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\t# 清零梯度，以便在下一次反向传播中不累积之前的梯度\n",
    "        loss.backward()\t\t# 进行反向传播，计算梯度\n",
    "        optimizer.step()\t# 根据梯度更新（优化）模型参数\n",
    " \n",
    "        # 定期输出训练信息\n",
    "        # 在每经过一定数量的批次后，输出当前训练轮次、总周轮数、当前批次、总批次数和损失值\n",
    "        if (i+1) % 400 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "        \t\t           .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\t# 指示 PyTorch 在接下来的代码块中不要计算梯度\n",
    "    # 初始化计数器\n",
    "    correct = 0\t\t# 正确分类的样本数\n",
    "    total = 0\t\t# 总样本数\n",
    " \n",
    "    # 遍历测试数据集的每个批次\n",
    "    for images, labels in test_loader:\n",
    "        # 将加载的图像和标签移动到设备（通常是 GPU）上\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    " \n",
    "        # 模型预测\n",
    "        outputs = model(images)\n",
    " \n",
    "        # 计算准确率\n",
    "        # 从模型输出中获取每个样本预测的类别\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # 累积总样本数\n",
    "        total += labels.size(0)\n",
    "        # 累积正确分类的样本数\n",
    "        correct += (predicted == labels).sum().item()\n",
    " \n",
    "    # 输出准确率，正确的 / 总的\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
